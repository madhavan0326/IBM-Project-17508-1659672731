{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.7.0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.2.4\n",
      "    Uninstalling Keras-2.2.4:\n",
      "      Successfully uninstalled Keras-2.2.4\n",
      "Successfully installed keras-2.7.0\n",
      "Collecting tensorflow==2.5.0\n",
      "  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 454.4 MB 29 kB/s s eta 0:00:01     |▏                               | 2.5 MB 11.6 MB/s eta 0:00:40[K     |▌                               | 7.0 MB 11.6 MB/s eta 0:00:39 MB 11.6 MB/s eta 0:00:393838| 266.0 MB 60.6 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 51.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 50.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.19.1)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 49.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.37.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.3.0)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 49.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.12.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.7.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 52.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (58.0.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.26.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.9.24)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.1)\n",
      "Installing collected packages: numpy, grpcio, typing-extensions, tensorflow-estimator, keras-nightly, h5py, flatbuffers, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Uninstalling typing-extensions-4.1.1:\n",
      "      Successfully uninstalled typing-extensions-4.1.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.7.0\n",
      "    Uninstalling tensorflow-estimator-2.7.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.2.1\n",
      "    Uninstalling h5py-3.2.1:\n",
      "      Successfully uninstalled h5py-3.2.1\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.7.2\n",
      "    Uninstalling tensorflow-2.7.2:\n",
      "      Successfully uninstalled tensorflow-2.7.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-text 2.7.3 requires tensorflow<2.8,>=2.7.0, but you have tensorflow 2.5.0 which is incompatible.\n",
      "pytorch-lightning 1.6.5 requires typing-extensions>=4.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "autoai-ts-libs 1.1.9 requires tensorflow<2.8,>=2.7.0; python_version >= \"3.9\", but you have tensorflow 2.5.0 which is incompatible.\u001b[0m\n",
      "Successfully installed flatbuffers-1.12 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.7.0\n",
    "!pip install tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='KXwPUSVBaJbZ_2hCJaG2h4CrhorzZWDO4M4tIrZCh2XN',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'fruittrainthemodelonibm-donotdelete-pr-3ccg0yghgs9vtm'\n",
    "object_key = 'fruit-dataset.zip'\n",
    "\n",
    "streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "if not hasattr(streaming_body_1,\"__iter__\"):streaming_body_1.__iter__=types.MethoType(__iter__,streaming_body_1)\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames=os.listdir(\"/home/wsuser/work/fruit-dataset/fruit-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5384 images belonging to 6 classes.\n",
      "Found 1686 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(\"/home/wsuser/work/fruit-dataset/fruit-dataset/train\",target_size=(128,128),batch_size=32,class_mode='categorical')\n",
    "x_test=test_datagen.flow_from_directory(\"/home/wsuser/work/fruit-dataset/fruit-dataset/test\",target_size=(128,128),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple___Black_rot': 0,\n",
       " 'Apple___healthy': 1,\n",
       " 'Corn_(maize)___Northern_Leaf_Blight': 2,\n",
       " 'Corn_(maize)___healthy': 3,\n",
       " 'Peach___Bacterial_spot': 4,\n",
       " 'Peach___healthy': 5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 127008)            0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(40,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "model.add(Dense(20,kernel_initializer = 'random_uniform',activation = 'relu'))\n",
    "model.add(Dense(6,kernel_initializer = 'random_uniform',activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "89/89 [==============================] - 40s 445ms/step - loss: 0.2755 - accuracy: 0.9016 - val_loss: 0.2302 - val_accuracy: 0.9259\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 40s 451ms/step - loss: 0.2590 - accuracy: 0.9073 - val_loss: 0.1864 - val_accuracy: 0.9306\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 41s 457ms/step - loss: 0.2376 - accuracy: 0.9175 - val_loss: 0.2033 - val_accuracy: 0.9398\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 39s 442ms/step - loss: 0.2416 - accuracy: 0.9157 - val_loss: 0.1931 - val_accuracy: 0.9363\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 39s 436ms/step - loss: 0.2076 - accuracy: 0.9274 - val_loss: 0.2201 - val_accuracy: 0.9236\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 39s 431ms/step - loss: 0.2008 - accuracy: 0.9281 - val_loss: 0.1829 - val_accuracy: 0.9387\n",
      "Epoch 7/20\n",
      "89/89 [==============================] - 39s 431ms/step - loss: 0.2083 - accuracy: 0.9345 - val_loss: 0.2117 - val_accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "89/89 [==============================] - 39s 432ms/step - loss: 0.1831 - accuracy: 0.9377 - val_loss: 0.1580 - val_accuracy: 0.9479\n",
      "Epoch 9/20\n",
      "89/89 [==============================] - 38s 425ms/step - loss: 0.1487 - accuracy: 0.9465 - val_loss: 0.1451 - val_accuracy: 0.9479\n",
      "Epoch 10/20\n",
      "89/89 [==============================] - 39s 434ms/step - loss: 0.1342 - accuracy: 0.9554 - val_loss: 0.2402 - val_accuracy: 0.9167\n",
      "Epoch 11/20\n",
      "89/89 [==============================] - 38s 428ms/step - loss: 0.1427 - accuracy: 0.9476 - val_loss: 0.2066 - val_accuracy: 0.9201\n",
      "Epoch 12/20\n",
      "89/89 [==============================] - 38s 424ms/step - loss: 0.1467 - accuracy: 0.9490 - val_loss: 0.1275 - val_accuracy: 0.9502\n",
      "Epoch 13/20\n",
      "89/89 [==============================] - 39s 436ms/step - loss: 0.1217 - accuracy: 0.9543 - val_loss: 0.1362 - val_accuracy: 0.9618\n",
      "Epoch 14/20\n",
      "89/89 [==============================] - 39s 433ms/step - loss: 0.1099 - accuracy: 0.9624 - val_loss: 0.0894 - val_accuracy: 0.9676\n",
      "Epoch 15/20\n",
      "89/89 [==============================] - 38s 423ms/step - loss: 0.0952 - accuracy: 0.9653 - val_loss: 0.1181 - val_accuracy: 0.9537\n",
      "Epoch 16/20\n",
      "89/89 [==============================] - 39s 434ms/step - loss: 0.1027 - accuracy: 0.9635 - val_loss: 0.1009 - val_accuracy: 0.9653\n",
      "Epoch 17/20\n",
      "89/89 [==============================] - 38s 426ms/step - loss: 0.1220 - accuracy: 0.9593 - val_loss: 0.0957 - val_accuracy: 0.9676\n",
      "Epoch 18/20\n",
      "89/89 [==============================] - 38s 429ms/step - loss: 0.0950 - accuracy: 0.9688 - val_loss: 0.0992 - val_accuracy: 0.9630\n",
      "Epoch 19/20\n",
      "89/89 [==============================] - 38s 423ms/step - loss: 0.0953 - accuracy: 0.9625 - val_loss: 0.0949 - val_accuracy: 0.9711\n",
      "Epoch 20/20\n",
      "89/89 [==============================] - 39s 439ms/step - loss: 0.1130 - accuracy: 0.9600 - val_loss: 0.0967 - val_accuracy: 0.9618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb3be3a3f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,steps_per_epoch=89,epochs=20,validation_data=x_test,validation_steps=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fruit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit.h5\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf fruit_disease_classification_model_new.tgz fruit.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mfruit-dataset\u001b[0m/\r\n",
      "fruit_disease_classification_model_new.tgz\r\n",
      "fruit.h5\r\n",
      "image-classification-model_new.tgz\r\n"
     ]
    }
   ],
   "source": [
    "ls -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watson-machine-learning-client in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.391)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\n",
      "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials={\"url\":\"https://us-south.ml.cloud.ibm.com\",\n",
    "                \"apikey\":\"dSpRL9UqZ0emOelK69G152fA493B5YuMkyOOm_8oXd06\"}\n",
    "client=APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client,space_name):\n",
    "    space=client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space UID =1999e64c-4df8-4b21-81fb-322eb8e3f338\n"
     ]
    }
   ],
   "source": [
    "space_uid=guid_from_space_name(client,'fruit_dis_clf')\n",
    "print(\"space UID =\" + space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------------------------------  ----\n",
      "NAME                           ASSET_ID                              TYPE\n",
      "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
      "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
      "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
      "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
      "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
      "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
      "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
      "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
      "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
      "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
      "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
      "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
      "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
      "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
      "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
      "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
      "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
      "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
      "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
      "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
      "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
      "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
      "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
      "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
      "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
      "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
      "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
      "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
      "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
      "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
      "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
      "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
      "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
      "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
      "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
      "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
      "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
      "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
      "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
      "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
      "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
      "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
      "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
      "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
      "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
      "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
      "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
      "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
      "runtime-22.2-py3.10-xc         5e8cddff-db4a-5a6a-b8aa-2d4af9864dab  base\n",
      "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
      "-----------------------------  ------------------------------------  ----\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_space_uid = client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mfruit-dataset\u001b[0m/                              fruit.h5\r\n",
      "fruit_disease_classification_model_new.tgz  image-classification-model_new.tgz\r\n"
     ]
    }
   ],
   "source": [
    " ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = client.repository.store_model(model= 'fruit_disease_classification_model_new.tgz',\n",
    "    meta_props={\n",
    "        client.repository.ModelMetaNames.NAME:\"CNN\",\n",
    "        client.repository.ModelMetaNames.TYPE:\"tensorflow_2.7\",\n",
    "        client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_space_uid}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = client.repository.get_model_id(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'580053fc-0029-45b9-9ac1-e9c8cb08288f'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mfruit-dataset\u001b[0m/                              fruit.h5\r\n",
      "fruit_disease_classification_model_new.tgz  image-classification-model_new.tgz\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model content to file: 'fruit_model.tar.gz'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work/fruit_model.tar.gz'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.download(model_id,\"fruit_model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('fruit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not StreamingBody",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/wsuser/ipykernel_164/2995498127.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming_body_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"__iter__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstreaming_body_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethoType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstreaming_body_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming_body_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    311\u001b[0m           \u001b[0mconsidered\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m           \u001b[0;32mor\u001b[0m \u001b[0malternatively\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcould\u001b[0m \u001b[0mspecify\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m           \u001b[0mvia\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m       \u001b[0mimage_data_generator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInstance\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m           \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0mtransformations\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not StreamingBody"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='KXwPUSVBaJbZ_2hCJaG2h4CrhorzZWDO4M4tIrZCh2XN',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'fruittrainthemodelonibm-donotdelete-pr-3ccg0yghgs9vtm'\n",
    "object_key = '0a553fc0-fc2c-4598-baba-3bc10191447c___RS_HL 5969.JPG'\n",
    "\n",
    "streaming_body_3 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "if not hasattr(streaming_body_3,\"__iter__\"):streaming_body_3.__iter__=types.MethoType(__iter__,streaming_body_3)\n",
    "    \n",
    "img=image.load_img(streaming_body_3,target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibm_botocore.response.StreamingBody at 0x7fb387af33d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_body_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '0a553fc0-fc2c-4598-baba-3bc10191447c___RS_HL 5969.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/wsuser/ipykernel_164/2088098598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0a553fc0-fc2c-4598-baba-3bc10191447c___RS_HL 5969.JPG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    311\u001b[0m           \u001b[0mconsidered\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m           \u001b[0;32mor\u001b[0m \u001b[0malternatively\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcould\u001b[0m \u001b[0mspecify\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m           \u001b[0mvia\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m       \u001b[0mimage_data_generator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInstance\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m           \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0mtransformations\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '0a553fc0-fc2c-4598-baba-3bc10191447c___RS_HL 5969.JPG'"
     ]
    }
   ],
   "source": [
    "img=image.load_img(streaming_body_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
